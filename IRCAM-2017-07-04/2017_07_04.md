build-lists: true

# IRCAM 
## Artistic Research Residency
## July 2017

---

# Thanks!

---

# About Me

I am James Bean.

---

# About Me

Sometimes I feel like

- a composer
- an audio engineer
- a performer of electronic music
- a programmer

---

# About Me

I am usually at Harvard where I study with:

- Chaya Czernowin
- Hans Tutschku

---

# As a composer

For a while, I was writing music like this:

^play sq2

---

![fit](img/sq/0.pdf)

^ 
Make sure audio is playing ...

---

![fit](img/sq/1.pdf)

---

![fit](img/sq/2.pdf)

---

![fit](img/sq/3.pdf)

---

![fit](img/sq/4.pdf)

---

![fit](img/sq/5.pdf)

---

![fit](img/sq/6.pdf)

---

![fit](img/sq/7.pdf)

---

![fit](img/sq/8.pdf)

---

![fit](img/sq/9.pdf)

---

# Why?

I was interested in:

- The physical repercussions of humans reasoning about things
- Intensifying the pragmatics of humans working together 
- Poking pretty hard at finding out what is "possible"
  - and whether that really means anything at all

I also thought it sounds nice.

---

# As a composer

My newer music has utilized simple digital and analog electronics sounds with live acoustic performers.

These works examine unexpected maskings and revelations when acoustic performers are playing very simple material amidst inundating electronic material.

Recordings to be posted somewhat soon.

---

# The Residency

- I started showing up here last summer
- I came back last winter
- I will be here for about another month

---

# The Project

**dn-m** (dynamic notation for music) strives to do a few things:

- Develop a productive model of non-staff notations
- Allow performers to redefine aspects of their notational environment in real-time
- Interact dynamically with their tablet, computer, or print it out

---

# The Project

A performer should be able to:

- Show / hide any musical information of their own or of others
- Annotate the score with their own markings
- Reorder the presentation of the notational elements
- Redefine representations of musical elements 
  - Pitch spellings, beaming, etc.

---

# The Project

They should be able to see:

- Built-in rehearsal tools deriving information latent in the score
  - Graphical and sonic metronomes, etc.
- Graphical feedback of interaction with real-time software
  - Antescofo

---

![fit](img/metronome_demo.mp4)

---

# Status

I am not done yet.

---

# What have I been working on?

At the time of that prototype, the code base was:

- Big
- Yet, poorly architected: highly-coupled
- A single block of totally unreusable code

---

# What have I been working on?

Since then, I have spent a great deal of time on the foundation.

- Many modules
- Fine-grained, composable network
- Enabling the creation of musical applications at various levels
- Decoupling from platform-specific APIs

---

# Modules

| **Score View Layer** |
| --- |
| **Score Model Layer** |
| **Musical Model Layer** |
| **Utility Layer** |

---

# Modules

**Utility Layer**

- `Collections`
- `ArithmeticTools`
- `GeometryTools`
- `PathTools`
- `GraphicsTools`
- `Timeline`

---

# Modules

**Musical Model Layer**

- `Pitch`
- `Rhythm`
- `Dynamics`
- `Articulations`
- `...`

---

# Modules

**Score Model Layer**

- `PitchSpellingTools`
- `RhythmSpellingTools`
- `PlotModel`
- `StaffModel`
- `...`

---

# Modules

**Score View Layer**

- `RhythmView`
- `DynamicsView`
- `PlotView`
- `StaffView`
- `...`

---

# Modules: Putting them together

- `Rhythm` + `Timeline` = `MetronomeController`

---

# TutschkuKit

Hans Tutschku has several pieces for live players and electronics which use iPad applications.

- These pieces require only an iPad and a pair of speakers
- All audio processing is done on the device
- To date, several applications rewritten in `Swift` with `dn-m` frameworks

---

# TutschkuKit

## _Example_

---

# Antescofo

Antescofo has an incredibly rich internal representation of mixed music.

Some of these internal representations still need to find ways of being represented graphically and intuitively.

---

# Musical Information Storage
### Work in Progress

For my introductory presentation, I presented a buggy prototype of a `Score Component Filter`.

This is a central aspect to the project, though the underlying storage strategy of musical information was working against me. 

In order to represent musical information in such a dynamic way, a different manner of storing musical information is necessary.

---

# Musical Information Storage
### Work in Progress

Many musical encodings have a hierarchical structure, which privilege a few types of views of musical material.

We are more interested in a model more like a database than an interchange format.

---

# Musical Information Storage
### Work in Progress

Going back to some of the performer-facing goals:

- Show / hide any musical information of their own or of others
- Annotate the score with their own markings
- Reorder the presentation of the notational elements
- Redefine representations of musical elements 
  - Pitch spellings, beaming, etc.

---

# Musical Information Storage
### Work in Progress

This database needs to be extensible as new types of musical information may be defined by a composer.

---

# Musical Information Storage
### Work in Progress

With the current implementation, it is simple and performant to retrieve all of the elements 

- within a given range of the score
- by a given performer (and instrument, and voice)
- of the given set of musical elements

---

# Musical Information Storage
### Work in Progress

Redefining representations aspects of the database is still to be implemented.

---

# Still to be done

- Input: `MusicXML`, `dn-m lang`, etc
- High-level drawing

---

Thanks!

---

Questions?

---

---